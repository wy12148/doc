# 存储引擎笔记

## 最简单的存储引擎

```bash
#!/bin/bash

db_set() {
  echo "$1,$2" >> database
}

db_get() {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

这其实就是一个简单的追加式文件结构（append-only file），或可将文件中存储的记录视为日志。每次通过 key 从文件中查询时，取出最新的一条记录即可得到目标数据。


## 哈希索引存储引擎（示例：Bitcask）

实现上的重要细节如下：

* 文件格式：二进制格式（段文件）
* 数据压缩：日志文件分为多个段（segment），当段文件达到一定大小时关闭并在新的段中写。后台线程会对已关闭的多个段进行合并与压缩，处理完后可以安全删除旧段并切换读取到合并后的段。
* 删除记录：在数据文件中追加特殊的删除记录（tombstone），合并时丢弃已删除键的所有值。
* 崩溃恢复：定期将每个段的 hash map 快照保存到磁盘，重启时加载快照以加速恢复。
* 部分写入的记录：追加记录过程中若发生崩溃，可通过校验值检测并丢弃损坏的记录。
* 并发控制：写入按严格先后顺序追加到文件，通常使用单写线程以保证顺序性。

局限性：

* 哈希表（索引）必须全部放入内存，数据量大时会占用大量内存。
* 区间查询效率低。


## LSM-Tree 存储引擎

LSM-Tree（Log-Structured Merge Tree）是一种基于合并与压缩排序文件的存储引擎。

### SSTable（Sorted String Table）

* 全称：Sorted String Table，排序字符串表。
* 要求：段文件中的 key-value 对按 key 排序，每个 key 在同一段文件中只能存在一次。

优点：

* 合并段高效：类似归并排序算法，同时读取多个输入段，比较各段的首项并按 key 顺序拷贝到输出文件。若多个段中存在相同 key，保留最新段的值并丢弃旧值。
* 不必在内存中保存所有 key 的索引，可使用稀疏索引结构。由于段文件有序，稀疏索引可定位大致范围后在段内扫描。
* 读请求常常需扫描范围内的多个 key-value 对，可将记录保存到块（block）并压缩，稀疏索引指向块的开头以提高效率。


### 构建和维护 SSTables

* 在内存中维护有序结构（例如红黑树或跳表）。
* 当内存表（memtable）超过阈值（通常几 MB）时，将其作为 SSTable 写入磁盘。内存表已保持按 key 排序，写磁盘较高效。写入过程中会创建新的内存表实例继续接受写操作。
* 读请求先在内存表中查找，然后按时间顺序查找最新的磁盘段文件，依次向更老的段查找直到命中或不存在。
* 后台线程周期性执行段合并（compaction），合并多个段并丢弃已被覆盖或删除的值。

若数据库崩溃，未刷入磁盘的内存表数据会丢失。为避免丢失，通常会保留顺序追加的日志（write-ahead log），每次写入都会追加到该日志。内存表写入 SSTable 后可删除相应的日志文件。

## 面向页的存储引擎（基于 B-Tree / B+Tree）

面向页（page-oriented）的存储引擎是关系型数据库中最常见的实现方式之一，典型代表如 InnoDB（MySQL）、PostgreSQL 的默认存储结构等。其核心思想是以固定大小的页（page）为单位进行磁盘 I/O、缓存和索引组织。

### 页（page）与磁盘布局

- 页是最小的 I/O 单位，通常大小为 4KB、8KB 或 16KB，由操作系统与 DBMS 配置决定。
- 数据页通常存储表的行记录或索引节点；索引页存储 B-Tree/B+Tree 的键与指针。
- 将数据按页组织，可减少随机 I/O 的频次，并将相关记录聚集到同一页以提高缓存命中率。

### B-Tree 与 B+Tree 的基本结构

- B-Tree：内部节点既包含键也包含记录或指向记录的指针。叶子节点与内部节点都可能存储实际数据。
- B+Tree：内部节点只存储键和指向子节点的指针，所有实际记录都保存在叶子节点。叶子节点通常通过链表相连，便于范围扫描和顺序访问。

优点对比（B-Tree vs B+Tree）：

- B+Tree 的叶子链表使范围查询与顺序扫描更高效；内部节点只存键让树更扁平、树高更低，从而减少 I/O。
- B-Tree 在某些场景下可以直接在内部节点找到完整记录，但通常因记录占用空间较大而导致树高增加。

### 插入、分裂与删除

- 插入：先在叶子页定位插入位置。若页有空间则直接插入并写回缓存（dirty page）。若页已满，则发生分裂（split）：
  - 将页分成两个页，中间 key 上升到父节点作为分隔。
  - 若父节点也满，则递归分裂，可能一直分裂到根，导致树高增加。
- 删除：在叶页删除记录后，若页中记录过少（低于阈值），则需要与相邻兄弟页合并或借键（borrow/redistribute）。合并会导致父节点删除一个键，可能递归触发父节点合并。

这些操作通常只修改少数几个页（局部性好），适合页级缓存与并发控制。

### 缓存（Buffer Pool）与写策略

- DBMS 通常维护一个 buffer pool（缓冲池）缓存经常访问或刚被修改的页。
- 修改页被标记为脏页（dirty）。针对脏页的写回策略主要有两类：
  - write-back：延迟写回，将脏页缓存在内存中，定期或按需（LRU、flush）写回磁盘。
  - write-through：每次修改直接同步写磁盘（性能较差，通常用于事务强一致要求少见）。
- 为保证事务的持久性，DBMS 通常结合 WAL（write-ahead log）机制：先将修改写入日志并刷盘（fsync），然后再将脏页延后写回数据文件。崩溃恢复通过 replay WAL 恢复未持久化的修改。

### IO 与范围查询

- B+Tree 在叶子链表中顺序排列记录，范围查询（range scan）可通过从起始叶子开始顺序读取相邻叶子完成，通常只需顺序读（顺序 I/O）和较少的随机 I/O。
- 对于点查（point lookup），通过索引树从根到叶的一次磁盘寻址（若缓存未命中）即可定位记录，平均 I/O 成本为树高（通常很小，例如 2~4 次页读）。

### 并发控制与锁

- 面向页的存储引擎常用的并发控制手段包括：
  - 页级锁（page-level locks）：锁住整个页，粒度较粗，降低并发度。
  - 行级锁（row-level locks）：在页内追踪行锁，实现更细粒度的并发控制（如 InnoDB 的行锁实现）。
  - 多版本并发控制（MVCC）：通过保存历史版本（undo log 或多版本链）实现无锁读，从而提高读操作并发性（例如 PostgreSQL、InnoDB 的 MVCC 设计）。

### 事务与一致性

- B-Tree/B+Tree 引擎通常与 WAL、锁或 MVCC 配合来实现 ACID 特性。插入/更新/删除 的原子性通过日志+锁或事务协议保证。

### 索引组织与聚集索引/非聚集索引

- 聚集索引（clustered index）：表数据按主键顺序存储在叶子页上（例如 InnoDB 的聚集索引），因此主键顺序即物理行顺序。
- 非聚集索引（secondary / non-clustered index）：索引的叶子页存储指向数据行的引用（如主键或行定位符），查找时需额外一次或多次 I/O 跳转到聚集数据页。

### 优缺点与何时选择

- 优点：
  - 适合点查和范围查询，范围扫描效率高；
  - 写放大较小（基于页的写通常只修改涉及页），适合 OLTP 场景；
  - 页级别的缓存与 MVCC 能提供较低延迟和高并发的读写性能。
- 缺点：
  - 写入会涉及随机 I/O（尤其在写放大较高或缓存不命中时）；
  - 在高写入吞吐或写入热点情况下需要复杂的锁或并发控制策略；
  - 合并/重分布（split/merge）会产生碎片，需要维护和重组织（reorg）。

与 LSM-Tree / 哈希 引擎对比：

- 与 LSM-Tree 相比：
  - LSM-Tree 写性能优秀（顺序写、写放大由 compaction 控制），适合写密集型场景；但 LSM 的读放大与范围查询性能在未优化时可能逊色于 B+Tree，且存在重读同一 key 的多次查找（需要 Bloom filter、稀疏索引优化）。
  - B+Tree 更适合延迟敏感的随机读写（OLTP），范围查询更直观高效。
- 与哈希引擎相比：
  - 哈希引擎点查非常快，但无法高效支持范围查询或排序；
  - B+Tree 兼顾点查与范围查，且在索引大小可控时也有良好性能。

### 实践建议

- 如果你的负载是写密集型且可以接受较高的写放大以及复杂的后台 compaction，LSM-Tree 是更优选择（例如日志/时序数据、写密集的键值存储）。
- 如果需要低延迟的随机读写与高效范围扫描（例如大多数 OLTP 应用），选择基于页的 B+Tree 引擎更合适。
